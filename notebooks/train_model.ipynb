{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af22aad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (3.10.5)\n",
      "Requirement already satisfied: seaborn in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: joblib in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: nltk in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: scikit-learn in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (1.7.1)\n",
      "Requirement already satisfied: matplotlib in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (3.10.5)\n",
      "Requirement already satisfied: seaborn in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (0.13.2)\n",
      "Requirement already satisfied: joblib in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (1.5.1)\n",
      "Requirement already satisfied: nltk in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (3.9.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (4.59.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: click in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: click in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nltk) (2025.11.3)\n",
      "Requirement already satisfied: tqdm in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/basar/.pyenv/versions/3.11.9/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!pip install pandas numpy scikit-learn matplotlib seaborn joblib nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50d67642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/basar/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/basar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf618aa",
   "metadata": {},
   "source": [
    "## 1. Load Processed Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c44be858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Loading datasets...\n",
      "\n",
      "‚ö† Nutrition dataset not found\n",
      "‚ö† Exercise dataset not found\n",
      "‚ö† Medical Q&A dataset not found\n",
      "‚ö† Pregnancy dataset not found\n",
      "‚ö† Women's Health dataset not found\n",
      "‚ö† Knowledge Base not found\n",
      "\n",
      "‚úÖ Datasets loaded successfully!\n",
      "‚ö† Women's Health dataset not found\n",
      "‚ö† Knowledge Base not found\n",
      "\n",
      "‚úÖ Datasets loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load all processed datasets\n",
    "print(\"üìÇ Loading datasets...\\n\")\n",
    "\n",
    "try:\n",
    "    df_nutrition = pd.read_csv('../datasets/processed/nutrition_processed.csv')\n",
    "    print(f\"‚úì Nutrition: {len(df_nutrition)} records\")\n",
    "except:\n",
    "    print(\"‚ö† Nutrition dataset not found\")\n",
    "    df_nutrition = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    df_exercise = pd.read_csv('../datasets/processed/exercise_processed.csv')\n",
    "    print(f\"‚úì Exercise: {len(df_exercise)} records\")\n",
    "except:\n",
    "    print(\"‚ö† Exercise dataset not found\")\n",
    "    df_exercise = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    df_qa = pd.read_csv('../datasets/processed/medical_qa_processed.csv')\n",
    "    print(f\"‚úì Medical Q&A: {len(df_qa)} records\")\n",
    "except:\n",
    "    print(\"‚ö† Medical Q&A dataset not found\")\n",
    "    df_qa = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    df_pregnancy = pd.read_csv('../datasets/processed/pregnancy_processed.csv')\n",
    "    print(f\"‚úì Pregnancy: {len(df_pregnancy)} records\")\n",
    "except:\n",
    "    print(\"‚ö† Pregnancy dataset not found\")\n",
    "    df_pregnancy = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    df_womens = pd.read_csv('../datasets/processed/womens_health_processed.csv')\n",
    "    print(f\"‚úì Women's Health: {len(df_womens)} records\")\n",
    "except:\n",
    "    print(\"‚ö† Women's Health dataset not found\")\n",
    "    df_womens = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    knowledge_base = pd.read_csv('../datasets/processed/knowledge_base.csv')\n",
    "    print(f\"‚úì Knowledge Base: {len(knowledge_base)} entries\")\n",
    "except:\n",
    "    print(\"‚ö† Knowledge Base not found\")\n",
    "    knowledge_base = pd.DataFrame()\n",
    "\n",
    "print(\"\\n‚úÖ Datasets loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bcf2b1",
   "metadata": {},
   "source": [
    "## 2. Train Q&A Model (TF-IDF + Cosine Similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2abd33c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Training Q&A Model...\n",
      "\n",
      "‚ùå No knowledge base available for training\n"
     ]
    }
   ],
   "source": [
    "print(\"ü§ñ Training Q&A Model...\\n\")\n",
    "\n",
    "if not knowledge_base.empty:\n",
    "    # Prepare Q&A data\n",
    "    questions = knowledge_base['question'].fillna('').tolist()\n",
    "    answers = knowledge_base['answer'].fillna('').tolist()\n",
    "    categories = knowledge_base['category'].fillna('general').tolist()\n",
    "    \n",
    "    # Create TF-IDF vectorizer\n",
    "    vectorizer = TfidfVectorizer(\n",
    "        max_features=500,\n",
    "        stop_words='english',\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=1\n",
    "    )\n",
    "    \n",
    "    # Fit on questions\n",
    "    question_vectors = vectorizer.fit_transform(questions)\n",
    "    \n",
    "    print(f\"‚úì Vectorizer trained on {len(questions)} questions\")\n",
    "    print(f\"‚úì Vocabulary size: {len(vectorizer.vocabulary_)}\")\n",
    "    \n",
    "    # Test the model\n",
    "    test_questions = [\n",
    "        \"How to improve health?\",\n",
    "        \"What is healthy blood sugar?\",\n",
    "        \"Best foods for heart?\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nüß™ Testing Q&A Model:\\n\")\n",
    "    for test_q in test_questions:\n",
    "        test_vec = vectorizer.transform([test_q])\n",
    "        similarities = cosine_similarity(test_vec, question_vectors)[0]\n",
    "        best_match_idx = similarities.argmax()\n",
    "        \n",
    "        if similarities[best_match_idx] > 0.1:\n",
    "            print(f\"Q: {test_q}\")\n",
    "            print(f\"A: {answers[best_match_idx][:100]}...\")\n",
    "            print(f\"Similarity: {similarities[best_match_idx]:.2f}\\n\")\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(vectorizer, '../models/qa_vectorizer.pkl')\n",
    "    \n",
    "    # Save Q&A database\n",
    "    qa_db = {\n",
    "        'questions': questions,\n",
    "        'answers': answers,\n",
    "        'categories': categories\n",
    "    }\n",
    "    joblib.dump(qa_db, '../models/qa_database.pkl')\n",
    "    \n",
    "    print(\"‚úÖ Q&A Model saved successfully!\")\n",
    "else:\n",
    "    print(\"‚ùå No knowledge base available for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9f80e6",
   "metadata": {},
   "source": [
    "## 3. Train Calorie Prediction Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b60def5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üçΩ Training Calorie Prediction Model...\n",
      "\n",
      "‚ùå Insufficient nutrition data for training\n"
     ]
    }
   ],
   "source": [
    "print(\"üçΩ Training Calorie Prediction Model...\\n\")\n",
    "\n",
    "if not df_nutrition.empty and 'protein' in df_nutrition.columns:\n",
    "    # Prepare features\n",
    "    X = df_nutrition[['protein', 'carbs', 'fat']]\n",
    "    y = df_nutrition['calories']\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    calorie_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    calorie_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = calorie_model.predict(X_test)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    print(f\"‚úì Model trained on {len(X_train)} samples\")\n",
    "    print(f\"‚úì R¬≤ Score: {r2:.4f}\")\n",
    "    print(f\"‚úì RMSE: {rmse:.2f} calories\\n\")\n",
    "    \n",
    "    # Test predictions\n",
    "    print(\"üß™ Test Predictions:\\n\")\n",
    "    for i in range(min(3, len(X_test))):\n",
    "        print(f\"Protein: {X_test.iloc[i]['protein']}g, Carbs: {X_test.iloc[i]['carbs']}g, Fat: {X_test.iloc[i]['fat']}g\")\n",
    "        print(f\"Predicted: {y_pred[i]:.0f} cal, Actual: {y_test.iloc[i]:.0f} cal\\n\")\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(calorie_model, '../models/calorie_predictor.pkl')\n",
    "    print(\"‚úÖ Calorie Prediction Model saved!\")\n",
    "else:\n",
    "    print(\"‚ùå Insufficient nutrition data for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b6f751",
   "metadata": {},
   "source": [
    "## 4. Train Exercise Recommendation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86a5aafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ Training Exercise Recommendation Model...\n",
      "\n",
      "‚ùå Insufficient exercise data for training\n"
     ]
    }
   ],
   "source": [
    "print(\"üèÉ Training Exercise Recommendation Model...\\n\")\n",
    "\n",
    "if not df_exercise.empty and 'body_weight' in df_exercise.columns:\n",
    "    # Prepare features\n",
    "    X = df_exercise[['body_weight', 'calories_per_hour']]\n",
    "    \n",
    "    # Encode exercise names\n",
    "    le_exercise = LabelEncoder()\n",
    "    y = le_exercise.fit_transform(df_exercise['exercise_name'])\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    exercise_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    exercise_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred = exercise_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    print(f\"‚úì Model trained on {len(X_train)} samples\")\n",
    "    print(f\"‚úì Accuracy: {accuracy:.4f}\\n\")\n",
    "    \n",
    "    # Save model\n",
    "    joblib.dump(exercise_model, '../models/exercise_recommender.pkl')\n",
    "    joblib.dump(le_exercise, '../models/exercise_encoder.pkl')\n",
    "    print(\"‚úÖ Exercise Recommendation Model saved!\")\n",
    "else:\n",
    "    print(\"‚ùå Insufficient exercise data for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff4bd1f",
   "metadata": {},
   "source": [
    "## 5. Create Health Advisor Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fe174a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè• Creating Health Advisor Knowledge Base...\n",
      "\n",
      "‚úÖ Health Knowledge Base created!\n",
      "\n",
      "üìä Knowledge Base contains:\n",
      "  - BMI Guidelines: 4 categories\n",
      "  - Blood Pressure: 3 categories\n",
      "  - Blood Glucose: 3 categories\n",
      "  - Daily Water Calculator\n",
      "  - Step Goals: 4 levels\n",
      "  - Sleep Recommendations\n"
     ]
    }
   ],
   "source": [
    "print(\"üè• Creating Health Advisor Knowledge Base...\\n\")\n",
    "\n",
    "# Combine all health knowledge\n",
    "health_knowledge = {\n",
    "    'bmi_ranges': {\n",
    "        'underweight': {'range': (0, 18.5), 'advice': 'Increase calorie intake with nutritious foods. Consult a nutritionist.'},\n",
    "        'normal': {'range': (18.5, 24.9), 'advice': 'Maintain current healthy lifestyle and balanced diet.'},\n",
    "        'overweight': {'range': (25, 29.9), 'advice': 'Reduce calorie intake, increase physical activity. Consider portion control.'},\n",
    "        'obese': {'range': (30, 100), 'advice': 'Consult healthcare provider. Focus on gradual weight loss through diet and exercise.'}\n",
    "    },\n",
    "    'blood_pressure': {\n",
    "        'normal': {'range': {'systolic': (90, 120), 'diastolic': (60, 80)}, 'advice': 'Maintain healthy lifestyle'},\n",
    "        'elevated': {'range': {'systolic': (120, 129), 'diastolic': (60, 80)}, 'advice': 'Reduce salt, exercise regularly'},\n",
    "        'high': {'range': {'systolic': (130, 200), 'diastolic': (80, 120)}, 'advice': 'Consult doctor, medication may be needed'}\n",
    "    },\n",
    "    'blood_glucose': {\n",
    "        'normal': {'range': (70, 100), 'advice': 'Maintain balanced diet and regular exercise'},\n",
    "        'prediabetes': {'range': (100, 125), 'advice': 'Reduce sugar intake, increase physical activity, monitor regularly'},\n",
    "        'diabetes': {'range': (126, 500), 'advice': 'Consult doctor immediately, medication and diet control essential'}\n",
    "    },\n",
    "    'daily_water': {\n",
    "        'formula': 'body_weight_kg * 0.033',  # liters\n",
    "        'min': 2.0,\n",
    "        'max': 4.0\n",
    "    },\n",
    "    'daily_steps': {\n",
    "        'sedentary': 5000,\n",
    "        'moderate': 7500,\n",
    "        'active': 10000,\n",
    "        'very_active': 12500\n",
    "    },\n",
    "    'sleep_hours': {\n",
    "        'adult': (7, 9),\n",
    "        'teenager': (8, 10),\n",
    "        'child': (9, 12)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add pregnancy knowledge\n",
    "if not df_pregnancy.empty:\n",
    "    pregnancy_dict = df_pregnancy.set_index('week').to_dict('index')\n",
    "    health_knowledge['pregnancy'] = pregnancy_dict\n",
    "\n",
    "# Add women's health knowledge\n",
    "if not df_womens.empty:\n",
    "    womens_health_dict = df_womens.set_index('symptom').to_dict('index')\n",
    "    health_knowledge['womens_health'] = womens_health_dict\n",
    "\n",
    "# Save knowledge base\n",
    "with open('../models/health_knowledge.json', 'w') as f:\n",
    "    json.dump(health_knowledge, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Health Knowledge Base created!\")\n",
    "print(f\"\\nüìä Knowledge Base contains:\")\n",
    "print(f\"  - BMI Guidelines: {len(health_knowledge['bmi_ranges'])} categories\")\n",
    "print(f\"  - Blood Pressure: {len(health_knowledge['blood_pressure'])} categories\")\n",
    "print(f\"  - Blood Glucose: {len(health_knowledge['blood_glucose'])} categories\")\n",
    "print(f\"  - Daily Water Calculator\")\n",
    "print(f\"  - Step Goals: {len(health_knowledge['daily_steps'])} levels\")\n",
    "print(f\"  - Sleep Recommendations\")\n",
    "if 'pregnancy' in health_knowledge:\n",
    "    print(f\"  - Pregnancy Guidance: {len(health_knowledge['pregnancy'])} weeks\")\n",
    "if 'womens_health' in health_knowledge:\n",
    "    print(f\"  - Women's Health: {len(health_knowledge['womens_health'])} symptoms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e4d256",
   "metadata": {},
   "source": [
    "## 6. Model Summary & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b22096a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "‚úÖ HealthNest AI Model Training Complete!\n",
      "============================================================\n",
      "\n",
      "üì¶ Trained Models:\n",
      "  1. Q&A Model (TF-IDF + Cosine Similarity)\n",
      "  2. Calorie Prediction Model (Random Forest Regressor)\n",
      "  3. Exercise Recommendation Model (Random Forest Classifier)\n",
      "  4. Health Knowledge Base (Rule-based System)\n",
      "\n",
      "üíæ Saved Files:\n",
      "  - ../models/qa_vectorizer.pkl\n",
      "  - ../models/qa_database.pkl\n",
      "  - ../models/calorie_predictor.pkl\n",
      "  - ../models/exercise_recommender.pkl\n",
      "  - ../models/exercise_encoder.pkl\n",
      "  - ../models/health_knowledge.json\n",
      "\n",
      "üìù Next Steps:\n",
      "  1. Test models using test_model.py\n",
      "  2. Deploy backend API using Flask\n",
      "  3. Build frontend chatbot UI\n",
      "  4. Integrate with HealthNest app\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"‚úÖ HealthNest AI Model Training Complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nüì¶ Trained Models:\")\n",
    "print(\"  1. Q&A Model (TF-IDF + Cosine Similarity)\")\n",
    "print(\"  2. Calorie Prediction Model (Random Forest Regressor)\")\n",
    "print(\"  3. Exercise Recommendation Model (Random Forest Classifier)\")\n",
    "print(\"  4. Health Knowledge Base (Rule-based System)\")\n",
    "\n",
    "print(\"\\nüíæ Saved Files:\")\n",
    "print(\"  - ../models/qa_vectorizer.pkl\")\n",
    "print(\"  - ../models/qa_database.pkl\")\n",
    "print(\"  - ../models/calorie_predictor.pkl\")\n",
    "print(\"  - ../models/exercise_recommender.pkl\")\n",
    "print(\"  - ../models/exercise_encoder.pkl\")\n",
    "print(\"  - ../models/health_knowledge.json\")\n",
    "\n",
    "print(\"\\nüìù Next Steps:\")\n",
    "print(\"  1. Test models using test_model.py\")\n",
    "print(\"  2. Deploy backend API using Flask\")\n",
    "print(\"  3. Build frontend chatbot UI\")\n",
    "print(\"  4. Integrate with HealthNest app\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7549139",
   "metadata": {},
   "source": [
    "## 7. Save Model Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0cab6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Model metadata saved!\n",
      "\n",
      "üìÑ View metadata: ../models/model_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Save model metadata\n",
    "metadata = {\n",
    "    'project': 'HealthNest AI Health Assistant',\n",
    "    'version': '1.0.0',\n",
    "    'date_trained': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'models': {\n",
    "        'qa_model': {\n",
    "            'type': 'TF-IDF + Cosine Similarity',\n",
    "            'knowledge_base_size': len(knowledge_base) if not knowledge_base.empty else 0,\n",
    "            'vocabulary_size': len(vectorizer.vocabulary_) if 'vectorizer' in locals() else 0\n",
    "        },\n",
    "        'calorie_predictor': {\n",
    "            'type': 'Random Forest Regressor',\n",
    "            'training_samples': len(X_train) if 'X_train' in locals() else 0,\n",
    "            'r2_score': r2 if 'r2' in locals() else None\n",
    "        },\n",
    "        'exercise_recommender': {\n",
    "            'type': 'Random Forest Classifier',\n",
    "            'accuracy': accuracy if 'accuracy' in locals() else None\n",
    "        }\n",
    "    },\n",
    "    'datasets': {\n",
    "        'nutrition': len(df_nutrition) if not df_nutrition.empty else 0,\n",
    "        'exercise': len(df_exercise) if not df_exercise.empty else 0,\n",
    "        'medical_qa': len(df_qa) if not df_qa.empty else 0,\n",
    "        'pregnancy': len(df_pregnancy) if not df_pregnancy.empty else 0,\n",
    "        'womens_health': len(df_womens) if not df_womens.empty else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('../models/model_metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Model metadata saved!\")\n",
    "print(\"\\nüìÑ View metadata: ../models/model_metadata.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
